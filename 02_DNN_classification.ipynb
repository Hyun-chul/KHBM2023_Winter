{"cells":[{"cell_type":"markdown","source":["This code was made by Juhyeon Lee, Ph.D. candidate (Feb. 7, 2023), Dept. of Brain and Cognitive Engineering, Korea University."],"metadata":{"id":"mpk6d935WiNt"}},{"cell_type":"markdown","source":["##  ※ \"런타임\" 클릭  >  \"런타임 유형 변경\" 클릭 > \"GPU\" "],"metadata":{"id":"PZFBbpkY1FS9"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"XQBr4FtYvp-Q"},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","from scipy import stats\n","import time\n","import seaborn as sns\n","import gc\n","import os \n","import random\n","from datetime import datetime as dt\n","from pytz import timezone\n","from sklearn.model_selection import ParameterGrid\n","import matplotlib.pyplot as plt\n","%matplotlib inline"]},{"cell_type":"markdown","metadata":{"id":"beirwroyvp-S"},"source":["# Mount Google drive"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6G-ybQJGvp-T","executionInfo":{"status":"ok","timestamp":1676421544966,"user_tz":-540,"elapsed":24336,"user":{"displayName":"Hyun-Chul Kim","userId":"14185916921863952694"}},"outputId":"ec9dab3d-cf53-486d-f218-1aef7e719d9b"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["# Mount your Google drive to the Google colab notebook \n","from google.colab import drive\n","drive.mount('/content/drive')\n","os.chdir('/content/drive/My Drive/Colab Notebooks/2023_KHBM_WinterSchool')"]},{"cell_type":"markdown","metadata":{"id":"ZsPsH1H2vp-T"},"source":["# Load input data"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MkFb6tZMvp-T","executionInfo":{"status":"ok","timestamp":1676421773301,"user_tz":-540,"elapsed":33322,"user":{"displayName":"Hyun-Chul Kim","userId":"14185916921863952694"}},"outputId":"56ebd13b-1207-45d0-9d33-ea9857c65f61"},"outputs":[{"output_type":"stream","name":"stdout","text":["(3200, 19900) (3200, 1)\n"]}],"source":["# !wget 'https://bspl.korea.ac.kr/Research_data/KNU2023/FC_input.npz'\n","from pydrive.auth import GoogleAuth \n","from pydrive.drive import GoogleDrive\n","from google.colab import auth\n","from oauth2client.client import GoogleCredentials\n","auth.authenticate_user()\n","gauth = GoogleAuth()\n","gauth.credentials = GoogleCredentials.get_application_default()\n","drive = GoogleDrive(gauth)\n","data_npz = drive.CreateFile({'id':'1zFf8EpcZ6Cqsk4K99hUovBNyTFai0fCS'})\n","data_npz.GetContentFile('FC_input.npz') \n"]},{"cell_type":"code","source":["fc_data = np.load('FC_input.npz')\n","\n","X = fc_data['x'] \n","X = np.arctanh(X)\n","X = stats.zscore(X, axis=1)\n","y = fc_data['y'].astype(np.float_).copy().reshape(-1, 1)\n","\n","print(X.shape,y.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VDXn4_lZhlPh","executionInfo":{"status":"ok","timestamp":1676421793266,"user_tz":-540,"elapsed":5490,"user":{"displayName":"Hyun-Chul Kim","userId":"14185916921863952694"}},"outputId":"a75e59cf-982e-46cc-b085-69181041801d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["(3200, 19900) (3200, 1)\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VLBBrtX7vp-U"},"outputs":[],"source":["sbjs = fc_data['sbjs']\n","all_sbjs = np.unique(sbjs)\n","np.random.shuffle(all_sbjs)\n","\n","train_sbjs = all_sbjs[0:80]\n","val_sbjs = all_sbjs[80:90]\n","test_sbjs = all_sbjs[90:100]\n","\n","train_sbjs_loc = np.in1d(sbjs,train_sbjs)\n","valid_sbjs_loc = np.in1d(sbjs,val_sbjs)\n","test_sbjs_loc = np.in1d(sbjs,test_sbjs)"]},{"cell_type":"markdown","metadata":{"id":"X-pJDlTvvp-U"},"source":["# Set hyperparameters"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lNmM3Tzovp-V"},"outputs":[],"source":["seed = 42\n","\n","learning_rate = 1e-5\n","min_lr = 1e-10\n","lr_patience = 10\n","momentum = 0.90\n","\n","l2_param = 5e-5\n","l1_param_cand = [5e-4,5e-5,5e-6]\n","param_cand = {\"l1_param\": l1_param_cand}\n","param_grid = list(ParameterGrid(param_cand))\n","param_grid\n","              \n","h1 = 512\n","h2 = 512\n","\n","dropout_h1 = 0.4\n","dropout_h2 = 0.4\n","\n","batch_size = 128\n","epochs = 300\n","print_epoch = 10\n","\n","input_dim = X.shape[1]\n","output_dim = 1"]},{"cell_type":"markdown","metadata":{"id":"L0zGORf2vp-V"},"source":["# Setup Pytorch"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6SdiXvRzvp-W"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","from torch.optim.lr_scheduler import ReduceLROnPlateau \n","from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler"]},{"cell_type":"markdown","metadata":{"id":"BYXSjSFgvp-W"},"source":["### Set CPU/GPU usage"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yV4nxaR4vp-W"},"outputs":[],"source":["num_workers = 2\n","\n","os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"   \n","os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n","use_cuda = torch.cuda.is_available()\n","device = torch.device(\"cuda\" if use_cuda else \"cpu\") "]},{"cell_type":"markdown","metadata":{"id":"Y7-K-5t6vp-W"},"source":["### Random seed"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pULntFR5vp-X"},"outputs":[],"source":["def seed_everything(seed=seed):\n","    random.seed(seed)\n","    os.environ['PYTHONHASHSEED'] = str(seed)\n","    np.random.seed(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)\n","    torch.backends.cudnn.deterministic = True\n","    torch.backends.cudnn.benchmark = True\n","seed_everything(seed)"]},{"cell_type":"markdown","metadata":{"id":"qKnj-jaqvp-X"},"source":["# Define functions"]},{"cell_type":"markdown","metadata":{"id":"hNnvaDbMvp-X"},"source":["### Define functions for data load"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Nwl2rYvcvp-X"},"outputs":[],"source":["class GetDataset(Dataset): \n","    def __init__(self, X, y):\n","        self.X = X\n","        self.y = y\n","        \n","    def __len__(self):\n","        return len(self.X)\n","    \n","    def __getitem__(self, idx): \n","        X = torch.from_numpy(self.X[idx]).type(torch.FloatTensor)\n","        y = torch.from_numpy(self.y[idx]).type(torch.FloatTensor)\n","\n","        return X, y"]},{"cell_type":"markdown","metadata":{"id":"gtkkGI6jvp-Y"},"source":["### Define functions for training/validaiton/test"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"x9xPapvRvp-Y"},"outputs":[],"source":["class DNN(nn.Module):\n","    def __init__(self, h1, h2, dropout_h1, dropout_h2):\n","        # 2 hidden layers\n","        super(DNN, self).__init__()\n","        self.ext_1 = nn.Linear(input_dim, h1)\n","        self.ext_bn_1 = nn.BatchNorm1d(h1)\n","        \n","        self.prd_1 = nn.Linear(h1, h2)\n","        self.prd_bn_1 = nn.BatchNorm1d(h2)\n","        self.prd_2 = nn.Linear(h2, output_dim)\n","        \n","        self.dropout_h1 = nn.Dropout(p=dropout_h1)\n","        self.dropout_h2 = nn.Dropout(p=dropout_h2)\n","        \n","        self.act_func = nn.Tanh()\n","        self.sigmoid = nn.Sigmoid()\n","        self.weights_init()\n","    \n","    def forward(self, x):\n","        x = self.ext_1(x)\n","        x = self.ext_bn_1(x)\n","        x = self.act_func(x)\n","        x = self.dropout_h1(x)\n","        \n","        x = self.prd_1(x)\n","        x = self.prd_bn_1(x)\n","        x = self.act_func(x)\n","        x = self.dropout_h2(x)\n","        x = self.prd_2(x)         \n","        out = self.sigmoid(x)\n","        \n","        return out\n","    \n","    def weights_init(self):\n","        for m in self.modules():\n","            if isinstance(m, nn.Linear):\n","                nn.init.kaiming_normal_(m.weight, mode=\"fan_in\", nonlinearity=\"relu\")\n","                nn.init.normal_(m.bias, std=0.01)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Af_6mbIJvp-Y"},"outputs":[],"source":["def train(model, epoch, train_loader, optimizer, criterion, l1_param, l2_param):\n","    model.train()\n","    train_loss = 0\n","    train_acc = 0\n","    cost = 0\n","    correct = 0\n","    total = 0\n","    \n","    for batch_idx, (input, target) in enumerate(train_loader):\n","        optimizer.zero_grad() \n","        input, target = input.to(device), target.to(device)\n","        pred, target = model(input), target.view(-1, 1)\n","        \n","        loss = criterion(pred, target)\n","        all_linear1_params = torch.cat([x.view(-1) for x in model.ext_1.parameters()])\n","        all_linear2_params = torch.cat([x.view(-1) for x in model.prd_1.parameters()])\n","        l1_regularization = l1_param * (torch.norm(all_linear1_params, 1) + torch.norm(all_linear2_params, 1))\n","        l2_regularization = l2_param * (torch.norm(all_linear1_params, 2) + torch.norm(all_linear2_params, 2))\n","\n","        cost = loss + l1_regularization + l2_regularization\n","        cost.backward()\n","        optimizer.step()\n","        train_loss += loss.item()\n","        total += pred.size(0)\n","                \n","        crite = torch.FloatTensor([0.5])\n","        crite = crite.to(device)\n","        prediction = pred >= crite  # 예측값이 0.5를 넘으면 True로 간주\n","        correct_prediction = prediction.float() == target # 실제값과 일치하는 경우만 True로 간주\n","        accuracy = correct_prediction.sum().item() / len(correct_prediction) # 정확도 계산\n","        correct += accuracy\n","        \n","    train_loss = train_loss / total\n","    train_acc = correct / (batch_idx+1)\n","\n","    return train_loss, train_acc"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QeGATetGvp-Y"},"outputs":[],"source":["def valid(model, epoch, valid_loader, criterion):\n","    model.eval()\n","    valid_loss = 0\n","    valid_acc = 0\n","    correct = 0\n","    total = 0\n","    \n","    with torch.no_grad():\n","        for input, target in valid_loader:\n","            input, target = input.to(device), target.to(device)\n","            pred, target = model(input), target.view(-1, 1)\n","            loss = criterion(pred, target)\n","            valid_loss += loss.item()\n","            total += pred.size(0)\n","            \n","            crite = torch.FloatTensor([0.5])\n","            crite = crite.to(device)\n","            prediction = pred >= crite # 예측값이 0.5를 넘으면 True로 간주\n","            correct_prediction = prediction.float() == target # 실제값과 일치하는 경우만 True로 간주\n","            accuracy = correct_prediction.sum().item() / len(correct_prediction) # 정확도 계산\n","            correct += accuracy\n","\n","    valid_acc = correct\n","    \n","    return valid_loss, valid_acc "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cixRSEhKvp-Z"},"outputs":[],"source":["def test(model, epoch, test_loader, criterion):\n","    model.eval()\n","    test_loss = 0\n","    test_acc = 0\n","    correct = 0\n","    total = 0\n","    \n","    with torch.no_grad():\n","        for input, target in test_loader:\n","            input, target = input.to(device), target.to(device)\n","            pred, target = model(input), target.view(-1, 1)\n","            loss = criterion(pred, target)\n","            test_loss += loss.item()\n","            total += pred.size(0)\n","            \n","            crite = torch.FloatTensor([0.5])\n","            crite = crite.to(device)\n","            prediction = pred >= crite  # 예측값이 0.5를 넘으면 True로 간주\n","            correct_prediction = prediction.float() == target # 실제값과 일치하는 경우만 True로 간주\n","            accuracy = correct_prediction.sum().item() / len(correct_prediction) # 정확도를 계산\n","            correct += accuracy\n","            \n","    test_acc = correct\n","\n","    return test_loss, test_acc "]},{"cell_type":"markdown","metadata":{"id":"ICKTenXVvp-Z"},"source":["### Define function for model training"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wRUSbLIOvp-Z"},"outputs":[],"source":["def run_train(params, i_model=0, rst_path=None, val_flg=0, print_epoch=10):\n","\n","    start_time = time.time()\n","\n","    X_train, y_train = X[train_sbjs_loc,:], y[train_sbjs_loc]\n","    X_valid, y_valid = X[valid_sbjs_loc,:], y[valid_sbjs_loc]\n","    X_test, y_test = X[test_sbjs_loc,:], y[test_sbjs_loc]\n","            \n","    train_dataset = GetDataset(X_train, y_train)\n","    valid_dataset = GetDataset(X_valid, y_valid)\n","    test_dataset = GetDataset(X_test, y_test)\n","    \n","    train_loader = DataLoader(\n","        train_dataset, batch_size=batch_size, pin_memory=True,\n","        shuffle=True, num_workers=num_workers, drop_last=True)\n","    valid_loader = DataLoader(\n","        valid_dataset, batch_size=len(y_valid), pin_memory=True,\n","        shuffle=True, num_workers=num_workers, drop_last=True)\n","    test_loader = DataLoader(\n","        test_dataset, batch_size=len(y_test), pin_memory=True,\n","        shuffle=True, num_workers=num_workers, drop_last=True)\n","        \n","    # Assign model \n","    model = DNN(h1, h2, dropout_h1, dropout_h2).to(device)\n","    optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, momentum=momentum, nesterov=True)\n","    scheduler = ReduceLROnPlateau(\n","        optimizer, mode=\"min\", patience=lr_patience, min_lr=min_lr\n","    )\n","    criterion = nn.functional.binary_cross_entropy\n","              \n","    # list to save learning parameters\n","    train_loss_list = []\n","    valid_loss_list = []\n","    train_acc_list = []\n","    valid_acc_list = []\n","    test_acc_list = []\n","\n","    for epoch in range(1, epochs + 1):\n","        train_loss, train_acc = train(\n","            model, epoch, train_loader, optimizer, criterion, params['l1_param'], l2_param\n","        )\n","        valid_loss, valid_acc = valid(model, epoch, valid_loader, criterion)\n","        test_loss, test_acc = test(model, epoch, test_loader, criterion)\n","\n","        scheduler.step(valid_loss)\n","        lr = optimizer.param_groups[0]['lr']\n","        \n","        train_loss_list.append(train_loss)\n","        train_acc_list.append(train_acc)\n","        valid_loss_list.append(valid_loss)\n","        valid_acc_list.append(valid_acc)\n","        \n","        if epoch % print_epoch == 0:\n","            print(\"Epoch [{:d}/{:d}]\".format(epoch, epochs), end=\" \")\n","            print(\"Lr: {:.1e}, Train loss: {:.4f}, Valid loss: {:.4f}, Train acc: {:.2f}, Valid acc: {:.2f}\"\n","                  .format(lr, train_loss, valid_loss, train_acc, valid_acc))\n","\n","            plot_learning_curves(\n","                rst_path, epochs, train_loss_list, valid_loss_list,  \n","                train_acc_list, valid_acc_list, i_model, val_flg=1\n","            )\n","    \n","    torch.save(model.state_dict(), \n","               rst_path + \"/model_\" + str(i_model+1) + \".pt\")\n","    \n","    torch.cuda.empty_cache()\n","    gc.collect()\n","    \n","    acc_list = [train_acc, valid_acc, test_acc]\n","\n","    tot_time = time.time() - start_time\n","    print(\"\\nExecution Time for model: {:.2f} mins\".format(tot_time / 60))\n","    \n","    return train_acc, valid_acc, test_acc"]},{"cell_type":"markdown","metadata":{"id":"Tof-fVsJvp-Z"},"source":["### Define functions for saving results"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"M1gNC46rvp-a"},"outputs":[],"source":["def plot_learning_curves(\n","    rst_path, epochs, train_loss, valid_loss, train_acc, valid_acc, i_model=0, val_flg=0):\n","    \n","    sns.set(style=\"darkgrid\", font_scale=2)\n","    fig, ax = plt.subplots(1, 2, figsize=(18, 10))\n","    ax = ax.flat\n","    lw = 4\n","    last_epoch = epochs\n","    \n","    ax[0].plot(train_loss[:last_epoch], label='train loss', lw=lw, color=\"r\")\n","    if val_flg:\n","        ax[0].plot(valid_loss[:last_epoch], label='valid loss', lw=lw, color=\"g\")\n","    ax[0].set_yscale('log')\n","    ax[0].legend()\n","    ax[0].set_title(\"Loss Plot\", pad=10)\n","\n","    ax[1].plot(train_acc[:last_epoch], label='train acc', lw=lw, color=\"r\")\n","    if val_flg:\n","        ax[1].plot(valid_acc[:last_epoch], label='valid acc', lw=lw, color=\"g\")\n","    ax[1].legend()\n","    ax[1].set_title(\"Accuracy Plot\", pad=10)\n","    \n","    fig.tight_layout()\n","    fig.savefig(\"{}/Learning_curves_model_{}.png\".format(rst_path,i_model+1))\n","    \n","    plt.close(fig)"]},{"cell_type":"markdown","metadata":{"id":"gXOcxdCyvp-a"},"source":["# Create directory & save model info"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FlSecUV5vp-a","executionInfo":{"status":"ok","timestamp":1676421815208,"user_tz":-540,"elapsed":282,"user":{"displayName":"Hyun-Chul Kim","userId":"14185916921863952694"}},"outputId":"2257566d-19a7-471b-fc66-ae1e43c14886"},"outputs":[{"output_type":"stream","name":"stdout","text":["result_20230215_094333\n"]}],"source":["nowtime = dt.now(timezone(\"Asia/Seoul\"))\n","\n","year = str(nowtime.year)\n","month = '0{}'.format(nowtime.month) if nowtime.month < 10 else str(nowtime.month)\n","day = '0{}'.format(nowtime.day) if nowtime.day < 10 else str(nowtime.day)\n","hour = '0{}'.format(nowtime.hour) if nowtime.hour < 10 else str(nowtime.hour)\n","minute = '0{}'.format(nowtime.minute) if nowtime.minute < 10 else str(nowtime.minute)\n","sec = '0{}'.format(nowtime.second) if nowtime.second < 10 else str(nowtime.second)\n","\n","save_path = \"result_{}{}{}_{}{}{}\".format(year,month,day,hour,minute,sec)\n","os.makedirs(save_path, exist_ok=True)\n","rst_path = \"{}/train_rst\".format(save_path)\n","os.makedirs(rst_path, exist_ok=True)\n","\n","\n","f = open(save_path+\"/info.txt\",'w')\n","f.write('seed : '+str(seed)+'\\n')\n","f.write('learning_rate : '+str(learning_rate)+'\\n')\n","f.write('min_lr : '+str(min_lr)+'\\n')\n","f.write('lr_patience : '+str(lr_patience)+'\\n')\n","f.write('momentum : '+str(momentum)+'\\n')\n","f.write('l2_param : '+str(l2_param)+'\\n')\n","f.write('dropout_h1 : '+str(dropout_h1)+'\\n')\n","f.write('dropout_h2 : '+str(dropout_h2)+'\\n')\n","f.write('batch_size : '+str(batch_size)+'\\n')\n","f.write('input_dim : '+str(input_dim)+'\\n')\n","f.write('output_dim : '+str(output_dim)+'\\n')\n","f.write('epochs : '+str(epochs)+'\\n')\n","f.close()\n","np.savez(save_path+'/sbj_shuffle',train_sbjs=train_sbjs,val_sbjs=val_sbjs,test_sbjs=test_sbjs)\n","\n","print(save_path)"]},{"cell_type":"markdown","metadata":{"id":"TR__0E2Ovp-a"},"source":["# Start training"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TOjXmRskvp-a","executionInfo":{"status":"ok","timestamp":1676422976538,"user_tz":-540,"elapsed":1159906,"user":{"displayName":"Hyun-Chul Kim","userId":"14185916921863952694"}},"outputId":"8af9a6e0-32ee-44e5-a193-d73647e216d4"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","<1> {'l1_param': 0.0005}\n","Epoch [10/300] Lr: 1.0e-05, Train loss: 0.0053, Valid loss: 0.5663, Train acc: 0.61, Valid acc: 0.73\n","Epoch [20/300] Lr: 1.0e-05, Train loss: 0.0045, Valid loss: 0.4761, Train acc: 0.71, Valid acc: 0.81\n","Epoch [30/300] Lr: 1.0e-05, Train loss: 0.0041, Valid loss: 0.4217, Train acc: 0.73, Valid acc: 0.84\n","Epoch [40/300] Lr: 1.0e-05, Train loss: 0.0037, Valid loss: 0.3839, Train acc: 0.77, Valid acc: 0.86\n","Epoch [50/300] Lr: 1.0e-05, Train loss: 0.0036, Valid loss: 0.3559, Train acc: 0.78, Valid acc: 0.87\n","Epoch [60/300] Lr: 1.0e-05, Train loss: 0.0034, Valid loss: 0.3344, Train acc: 0.80, Valid acc: 0.88\n","Epoch [70/300] Lr: 1.0e-05, Train loss: 0.0032, Valid loss: 0.3174, Train acc: 0.81, Valid acc: 0.87\n","Epoch [80/300] Lr: 1.0e-05, Train loss: 0.0029, Valid loss: 0.3025, Train acc: 0.84, Valid acc: 0.88\n","Epoch [90/300] Lr: 1.0e-05, Train loss: 0.0028, Valid loss: 0.2907, Train acc: 0.85, Valid acc: 0.88\n","Epoch [100/300] Lr: 1.0e-05, Train loss: 0.0027, Valid loss: 0.2803, Train acc: 0.84, Valid acc: 0.88\n","Epoch [110/300] Lr: 1.0e-05, Train loss: 0.0026, Valid loss: 0.2711, Train acc: 0.86, Valid acc: 0.89\n","Epoch [120/300] Lr: 1.0e-05, Train loss: 0.0025, Valid loss: 0.2631, Train acc: 0.87, Valid acc: 0.89\n","Epoch [130/300] Lr: 1.0e-05, Train loss: 0.0024, Valid loss: 0.2560, Train acc: 0.86, Valid acc: 0.88\n","Epoch [140/300] Lr: 1.0e-05, Train loss: 0.0024, Valid loss: 0.2492, Train acc: 0.88, Valid acc: 0.89\n","Epoch [150/300] Lr: 1.0e-05, Train loss: 0.0023, Valid loss: 0.2436, Train acc: 0.88, Valid acc: 0.89\n","Epoch [160/300] Lr: 1.0e-05, Train loss: 0.0022, Valid loss: 0.2378, Train acc: 0.89, Valid acc: 0.89\n","Epoch [170/300] Lr: 1.0e-05, Train loss: 0.0022, Valid loss: 0.2331, Train acc: 0.89, Valid acc: 0.89\n","Epoch [180/300] Lr: 1.0e-05, Train loss: 0.0022, Valid loss: 0.2285, Train acc: 0.89, Valid acc: 0.89\n","Epoch [190/300] Lr: 1.0e-05, Train loss: 0.0020, Valid loss: 0.2247, Train acc: 0.91, Valid acc: 0.89\n","Epoch [200/300] Lr: 1.0e-05, Train loss: 0.0020, Valid loss: 0.2208, Train acc: 0.90, Valid acc: 0.89\n","Epoch [210/300] Lr: 1.0e-05, Train loss: 0.0020, Valid loss: 0.2171, Train acc: 0.91, Valid acc: 0.89\n","Epoch [220/300] Lr: 1.0e-05, Train loss: 0.0019, Valid loss: 0.2134, Train acc: 0.91, Valid acc: 0.90\n","Epoch [230/300] Lr: 1.0e-05, Train loss: 0.0019, Valid loss: 0.2102, Train acc: 0.91, Valid acc: 0.90\n","Epoch [240/300] Lr: 1.0e-05, Train loss: 0.0018, Valid loss: 0.2076, Train acc: 0.92, Valid acc: 0.90\n","Epoch [250/300] Lr: 1.0e-05, Train loss: 0.0018, Valid loss: 0.2048, Train acc: 0.92, Valid acc: 0.90\n","Epoch [260/300] Lr: 1.0e-05, Train loss: 0.0017, Valid loss: 0.2023, Train acc: 0.92, Valid acc: 0.90\n","Epoch [270/300] Lr: 1.0e-05, Train loss: 0.0017, Valid loss: 0.1998, Train acc: 0.92, Valid acc: 0.90\n","Epoch [280/300] Lr: 1.0e-05, Train loss: 0.0016, Valid loss: 0.1977, Train acc: 0.93, Valid acc: 0.90\n","Epoch [290/300] Lr: 1.0e-05, Train loss: 0.0016, Valid loss: 0.1951, Train acc: 0.92, Valid acc: 0.90\n","Epoch [300/300] Lr: 1.0e-05, Train loss: 0.0017, Valid loss: 0.1931, Train acc: 0.92, Valid acc: 0.90\n","\n","Execution Time for model: 5.47 mins\n","\n","<2> {'l1_param': 5e-05}\n","Epoch [10/300] Lr: 1.0e-05, Train loss: 0.0051, Valid loss: 0.5618, Train acc: 0.64, Valid acc: 0.71\n","Epoch [20/300] Lr: 1.0e-05, Train loss: 0.0046, Valid loss: 0.4786, Train acc: 0.69, Valid acc: 0.78\n","Epoch [30/300] Lr: 1.0e-05, Train loss: 0.0040, Valid loss: 0.4281, Train acc: 0.74, Valid acc: 0.82\n","Epoch [40/300] Lr: 1.0e-05, Train loss: 0.0038, Valid loss: 0.3933, Train acc: 0.76, Valid acc: 0.83\n","Epoch [50/300] Lr: 1.0e-05, Train loss: 0.0035, Valid loss: 0.3673, Train acc: 0.79, Valid acc: 0.86\n","Epoch [60/300] Lr: 1.0e-05, Train loss: 0.0034, Valid loss: 0.3463, Train acc: 0.80, Valid acc: 0.86\n","Epoch [70/300] Lr: 1.0e-05, Train loss: 0.0032, Valid loss: 0.3293, Train acc: 0.81, Valid acc: 0.87\n","Epoch [80/300] Lr: 1.0e-05, Train loss: 0.0031, Valid loss: 0.3154, Train acc: 0.82, Valid acc: 0.88\n","Epoch [90/300] Lr: 1.0e-05, Train loss: 0.0029, Valid loss: 0.3034, Train acc: 0.83, Valid acc: 0.89\n","Epoch [100/300] Lr: 1.0e-05, Train loss: 0.0028, Valid loss: 0.2924, Train acc: 0.85, Valid acc: 0.89\n","Epoch [110/300] Lr: 1.0e-05, Train loss: 0.0026, Valid loss: 0.2830, Train acc: 0.86, Valid acc: 0.90\n","Epoch [120/300] Lr: 1.0e-05, Train loss: 0.0026, Valid loss: 0.2746, Train acc: 0.86, Valid acc: 0.90\n","Epoch [130/300] Lr: 1.0e-05, Train loss: 0.0025, Valid loss: 0.2674, Train acc: 0.86, Valid acc: 0.91\n","Epoch [140/300] Lr: 1.0e-05, Train loss: 0.0023, Valid loss: 0.2597, Train acc: 0.88, Valid acc: 0.91\n","Epoch [150/300] Lr: 1.0e-05, Train loss: 0.0023, Valid loss: 0.2537, Train acc: 0.88, Valid acc: 0.91\n","Epoch [160/300] Lr: 1.0e-05, Train loss: 0.0022, Valid loss: 0.2481, Train acc: 0.89, Valid acc: 0.91\n","Epoch [170/300] Lr: 1.0e-05, Train loss: 0.0021, Valid loss: 0.2431, Train acc: 0.90, Valid acc: 0.91\n","Epoch [180/300] Lr: 1.0e-05, Train loss: 0.0022, Valid loss: 0.2380, Train acc: 0.89, Valid acc: 0.91\n","Epoch [190/300] Lr: 1.0e-05, Train loss: 0.0020, Valid loss: 0.2336, Train acc: 0.90, Valid acc: 0.91\n","Epoch [200/300] Lr: 1.0e-05, Train loss: 0.0020, Valid loss: 0.2296, Train acc: 0.90, Valid acc: 0.92\n","Epoch [210/300] Lr: 1.0e-05, Train loss: 0.0020, Valid loss: 0.2256, Train acc: 0.90, Valid acc: 0.92\n","Epoch [220/300] Lr: 1.0e-05, Train loss: 0.0019, Valid loss: 0.2218, Train acc: 0.91, Valid acc: 0.93\n","Epoch [230/300] Lr: 1.0e-05, Train loss: 0.0018, Valid loss: 0.2184, Train acc: 0.91, Valid acc: 0.93\n","Epoch [240/300] Lr: 1.0e-05, Train loss: 0.0018, Valid loss: 0.2151, Train acc: 0.91, Valid acc: 0.93\n","Epoch [250/300] Lr: 1.0e-05, Train loss: 0.0018, Valid loss: 0.2124, Train acc: 0.91, Valid acc: 0.93\n","Epoch [260/300] Lr: 1.0e-05, Train loss: 0.0017, Valid loss: 0.2093, Train acc: 0.92, Valid acc: 0.93\n","Epoch [270/300] Lr: 1.0e-05, Train loss: 0.0017, Valid loss: 0.2064, Train acc: 0.92, Valid acc: 0.93\n","Epoch [280/300] Lr: 1.0e-05, Train loss: 0.0018, Valid loss: 0.2040, Train acc: 0.91, Valid acc: 0.93\n","Epoch [290/300] Lr: 1.0e-05, Train loss: 0.0017, Valid loss: 0.2013, Train acc: 0.92, Valid acc: 0.93\n","Epoch [300/300] Lr: 1.0e-05, Train loss: 0.0017, Valid loss: 0.1992, Train acc: 0.92, Valid acc: 0.93\n","\n","Execution Time for model: 6.43 mins\n","\n","<3> {'l1_param': 5e-06}\n","Epoch [10/300] Lr: 1.0e-05, Train loss: 0.0055, Valid loss: 0.5690, Train acc: 0.60, Valid acc: 0.72\n","Epoch [20/300] Lr: 1.0e-05, Train loss: 0.0048, Valid loss: 0.4738, Train acc: 0.68, Valid acc: 0.78\n","Epoch [30/300] Lr: 1.0e-05, Train loss: 0.0043, Valid loss: 0.4180, Train acc: 0.73, Valid acc: 0.82\n","Epoch [40/300] Lr: 1.0e-05, Train loss: 0.0040, Valid loss: 0.3814, Train acc: 0.75, Valid acc: 0.83\n","Epoch [50/300] Lr: 1.0e-05, Train loss: 0.0036, Valid loss: 0.3542, Train acc: 0.77, Valid acc: 0.85\n","Epoch [60/300] Lr: 1.0e-05, Train loss: 0.0034, Valid loss: 0.3321, Train acc: 0.79, Valid acc: 0.86\n","Epoch [70/300] Lr: 1.0e-05, Train loss: 0.0032, Valid loss: 0.3151, Train acc: 0.81, Valid acc: 0.88\n","Epoch [80/300] Lr: 1.0e-05, Train loss: 0.0030, Valid loss: 0.3005, Train acc: 0.82, Valid acc: 0.88\n","Epoch [90/300] Lr: 1.0e-05, Train loss: 0.0029, Valid loss: 0.2880, Train acc: 0.85, Valid acc: 0.89\n","Epoch [100/300] Lr: 1.0e-05, Train loss: 0.0028, Valid loss: 0.2779, Train acc: 0.84, Valid acc: 0.90\n","Epoch [110/300] Lr: 1.0e-05, Train loss: 0.0027, Valid loss: 0.2687, Train acc: 0.85, Valid acc: 0.90\n","Epoch [120/300] Lr: 1.0e-05, Train loss: 0.0025, Valid loss: 0.2605, Train acc: 0.87, Valid acc: 0.91\n","Epoch [130/300] Lr: 1.0e-05, Train loss: 0.0026, Valid loss: 0.2528, Train acc: 0.86, Valid acc: 0.90\n","Epoch [140/300] Lr: 1.0e-05, Train loss: 0.0025, Valid loss: 0.2462, Train acc: 0.87, Valid acc: 0.90\n","Epoch [150/300] Lr: 1.0e-05, Train loss: 0.0023, Valid loss: 0.2407, Train acc: 0.88, Valid acc: 0.90\n","Epoch [160/300] Lr: 1.0e-05, Train loss: 0.0024, Valid loss: 0.2354, Train acc: 0.87, Valid acc: 0.90\n","Epoch [170/300] Lr: 1.0e-05, Train loss: 0.0022, Valid loss: 0.2305, Train acc: 0.89, Valid acc: 0.90\n","Epoch [180/300] Lr: 1.0e-05, Train loss: 0.0022, Valid loss: 0.2254, Train acc: 0.89, Valid acc: 0.90\n","Epoch [190/300] Lr: 1.0e-05, Train loss: 0.0021, Valid loss: 0.2214, Train acc: 0.90, Valid acc: 0.90\n","Epoch [200/300] Lr: 1.0e-05, Train loss: 0.0021, Valid loss: 0.2171, Train acc: 0.90, Valid acc: 0.91\n","Epoch [210/300] Lr: 1.0e-05, Train loss: 0.0020, Valid loss: 0.2131, Train acc: 0.90, Valid acc: 0.91\n","Epoch [220/300] Lr: 1.0e-05, Train loss: 0.0020, Valid loss: 0.2097, Train acc: 0.90, Valid acc: 0.91\n","Epoch [230/300] Lr: 1.0e-05, Train loss: 0.0019, Valid loss: 0.2063, Train acc: 0.91, Valid acc: 0.91\n","Epoch [240/300] Lr: 1.0e-05, Train loss: 0.0019, Valid loss: 0.2032, Train acc: 0.91, Valid acc: 0.92\n","Epoch [250/300] Lr: 1.0e-05, Train loss: 0.0018, Valid loss: 0.2008, Train acc: 0.91, Valid acc: 0.92\n","Epoch [260/300] Lr: 1.0e-05, Train loss: 0.0018, Valid loss: 0.1977, Train acc: 0.91, Valid acc: 0.92\n","Epoch [270/300] Lr: 1.0e-05, Train loss: 0.0017, Valid loss: 0.1955, Train acc: 0.92, Valid acc: 0.93\n","Epoch [280/300] Lr: 1.0e-05, Train loss: 0.0017, Valid loss: 0.1931, Train acc: 0.93, Valid acc: 0.93\n","Epoch [290/300] Lr: 1.0e-05, Train loss: 0.0016, Valid loss: 0.1910, Train acc: 0.93, Valid acc: 0.93\n","Epoch [300/300] Lr: 1.0e-05, Train loss: 0.0017, Valid loss: 0.1888, Train acc: 0.93, Valid acc: 0.93\n","\n","Execution Time for model: 7.43 mins\n","\n","<2> Selected {'l1_param': 5e-05}, train acc: 0.9203, valid acc: 0.9313, test acc: 0.8844\n"]}],"source":["all_acc_list = []\n","for i_model,params in enumerate(param_grid):\n","\n","    print(\"\\n<{}> {}\".format(i_model+1,params))\n","    train_acc_model, valid_acc_model, test_acc_model = run_train(\n","        params, i_model, rst_path, val_flg = 0, print_epoch=print_epoch\n","    )\n","    all_acc_list.append([params, train_acc_model, valid_acc_model, test_acc_model])\n","\n","        \n","acc_df = pd.DataFrame(np.array(all_acc_list), columns=[\"params\",\"train_acc\", \"valid_acc\", \"test_acc\"])\n","acc_df.to_csv(\"{}/params_acc.csv\".format(rst_path))\n","\n","all_valid_acc = [item[2] for item in all_acc_list]\n","selected_model = np.argmax(all_valid_acc)\n","\n","print(\"\\n<{}> Selected {}, train acc: {:.4f}, valid acc: {:.4f}, test acc: {:.4f}\"\n","      .format(selected_model+1, param_grid[selected_model], all_acc_list[selected_model][1], all_acc_list[selected_model][2], all_acc_list[selected_model][3]))"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.10"},"colab":{"provenance":[]},"accelerator":"GPU","gpuClass":"standard"},"nbformat":4,"nbformat_minor":0}